{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from botorch.models.model import Model\n",
    "from botorch.utils import t_batch_mode_transform\n",
    "from torch import Tensor\n",
    "from botorch.models.model_list_gp_regression import ModelListGP\n",
    "import torch\n",
    "from botorch.models import  FixedNoiseGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.utils import standardize\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "from botorch.acquisition import AnalyticAcquisitionFunction\n",
    "from botorch.acquisition import MCAcquisitionFunction\n",
    "from botorch.optim.optimize import optimize_acqf\n",
    "from botorch.optim.initializers import gen_batch_initial_conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the acquisition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.acquisition import AnalyticAcquisitionFunction\n",
    "import torch\n",
    "\n",
    "class HyperVolumeScalarizedUCB(AnalyticAcquisitionFunction):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        beta: float,\n",
    "        theta: torch.Tensor,\n",
    "        ref: torch.Tensor,\n",
    "        maximize: bool = True,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the HyperVolume Scalarized Upper Confidence Bound Acquisition Function.\n",
    "\n",
    "        Args:\n",
    "            model: A BoTorch model representing the posterior distribution of the objectives.\n",
    "            beta (Tensor of shape [1] or [o]): The exploration-exploitation trade-off parameter(s).\n",
    "            theta (Tensor of shape [o]): The weights used for scalarizing the upper bounds, where `o` is the number of objectives.\n",
    "            maximize (bool): Whether to maximize or minimize the scalarized objective. Defaults to True (maximize).\n",
    "        \"\"\"\n",
    "        super(AnalyticAcquisitionFunction, self).__init__(model)\n",
    "        self.maximize = maximize\n",
    "        self.register_buffer(\"beta\", torch.as_tensor(beta))\n",
    "        self.register_buffer(\"theta\", torch.as_tensor(theta))\n",
    "        self.register_buffer(\"ref\", torch.as_tensor(ref))\n",
    "    @t_batch_mode_transform(expected_q=1)\n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluate the scalarized Upper Confidence Bound on the candidate set X.\n",
    "\n",
    "        Args:\n",
    "            X (Tensor of shape [b, d]): A tensor containing `(b)` batches of `d`-dimensional design points.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape [b]: A tensor containing the scalarized Upper Confidence Bound values for each batch.\n",
    "        \"\"\"\n",
    "        self.beta = self.beta.to(X)\n",
    "        self.theta = self.theta.to(X)\n",
    "        self.ref = self.ref.to(X)\n",
    "        posterior = self.model.posterior(X)\n",
    "        means = posterior.mean.squeeze(dim=-2)  # b x o\n",
    "        std_devs = posterior.variance.squeeze(dim=-2).sqrt()  # b x o\n",
    "        m = means.shape[1]\n",
    "        # Calculate upper confidence bounds for each objective\n",
    "        u_t = means + (self.beta.expand_as(means) * std_devs) - self.ref # b x o\n",
    "\n",
    "        # Apply the scalarization function to the upper bounds\n",
    "        scalarized_ut = torch.min(torch.max(torch.zeros_like(u_t), u_t / self.theta) ** m, dim=-1)[0]  # b\n",
    "\n",
    "        return scalarized_ut\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the auxiliary acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxiliaryAcq(MCAcquisitionFunction):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        beta: float,\n",
    "        theta: torch.Tensor,\n",
    "        ref: torch.Tensor,\n",
    "        maximize: bool = True,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        An auxiliary acquisition defined in Algo.2\n",
    "\n",
    "        Args:\n",
    "            model: A BoTorch model representing the posterior distribution of the objectives.\n",
    "            beta (Tensor of shape [1] or [o]): The exploration-exploitation trade-off parameter(s).\n",
    "            theta (Tensor of shape [o]): The weights used for scalarizing the upper bounds, where `o` is the number of objectives.\n",
    "            maximize (bool): Whether to maximize or minimize the scalarized objective. Defaults to True (maximize).\n",
    "        \"\"\"\n",
    "        super(MCAcquisitionFunction, self).__init__(model)\n",
    "        self.maximize = maximize\n",
    "        self.register_buffer(\"beta\", torch.as_tensor(beta))\n",
    "        self.register_buffer(\"theta\", torch.as_tensor(theta))\n",
    "        self.register_buffer(\"ref\", torch.as_tensor(ref))\n",
    "    @t_batch_mode_transform()\n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluate the scalarized Upper Confidence Bound on the candidate set X.\n",
    "\n",
    "        Args:\n",
    "            X (Tensor of shape [b, d]): A tensor containing `(b)` batches of `d`-dimensional design points.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape [b]: A tensor containing the scalarized Upper Confidence Bound values for each batch.\n",
    "        \"\"\"\n",
    "        self.beta = self.beta.to(X)\n",
    "        self.theta = self.theta.to(X)\n",
    "        self.ref = self.ref.to(X)\n",
    "        posterior = self.model.posterior(X)\n",
    "        #print(posterior.mean.shape)\n",
    "        means = posterior.mean  # b x q x o\n",
    "        std_devs = posterior.variance.sqrt()  # b x q x o\n",
    "        # Calculate upper confidence bounds for each objective\n",
    "        u_t = means + (self.beta.expand_as(means) * std_devs) - self.ref # b x qx o\n",
    "        #print('233', u_t.shape)\n",
    "\n",
    "        # Apply the scalarization function to the upper bounds\n",
    "        scalarized_ut = torch.max(torch.min(u_t, dim=-1)[0], dim=-1)[0]  # b\n",
    "        print('22', scalarized_ut.shape)\n",
    "\n",
    "        return scalarized_ut\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check feasibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- optimize the posterior calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ucb_constraints(model, beta: float, thresholds: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Creates a list of non-linear inequality constraints for a multi-output GP model, ensuring that the upper confidence\n",
    "    bounds of the model's outputs are greater than or equal to the specified thresholds.\n",
    "\n",
    "    Args:\n",
    "        model (MultiTaskGP): A multi-output Gaussian Process model.\n",
    "        beta (float): The scalar coefficient for the variance component of the UCB.\n",
    "        thresholds (torch.Tensor): A tensor of thresholds for each output dimension.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[Callable, bool]]: A list of tuples, each containing a callable constraint and a boolean indicating\n",
    "                                      whether the constraint is intra-point (True) or inter-point (False). Each callable\n",
    "                                      takes a tensor `X` of shape [q, d] (where `d` is the dimension of the input space\n",
    "                                      and `q` can be 1 or more representing different design points) and returns a scalar\n",
    "                                      that should be non-negative if the constraint is satisfied.\n",
    "    \"\"\"\n",
    "\n",
    "    def make_constraint(i, threshold):\n",
    "        \"\"\"\n",
    "        Creates a constraint function for the i-th objective.\n",
    "\n",
    "        Args:\n",
    "            i (int): The index of the output dimension for which to create the constraint.\n",
    "            threshold (float): The threshold value that the UCB of the i-th output should meet.\n",
    "\n",
    "        Returns:\n",
    "            Callable: A function that evaluates the constraint across a batch of design points.\n",
    "        \"\"\"\n",
    "        def constraint(X):\n",
    "            X = X.unsqueeze(0)\n",
    "            # Compute posterior at X\n",
    "            posterior = model.posterior(X)\n",
    "            mean = posterior.mean[:, i]  # Extract the mean for the i-th output\n",
    "            variance = posterior.variance[:, i]  # Extract the variance for the i-th output\n",
    "            ucb = mean + beta * variance.sqrt()  # Compute the UCB\n",
    "\n",
    "            # Minimum across all points in the batch to satisfy the constraint for any single design point\n",
    "            return ucb - threshold\n",
    "\n",
    "        return constraint\n",
    "\n",
    "    # Create a list of constraints for each output dimension, all set as intra-point since they evaluate individually\n",
    "    constraints = [(make_constraint(i, thresholds[i]), True) for i in range(thresholds.size(0))]\n",
    "\n",
    "    return constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sphere point generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_sample_on_n_sphere(N, R):\n",
    "    # Return a single sample of a vector of dimension N\n",
    "    # with a uniform distribution on the (N-1)-Sphere surface of radius R.\n",
    "    # RATIONALE: https://mathworld.wolfram.com/HyperspherePointPicking.html\n",
    "    \n",
    "    # Generate a normally distributed point\n",
    "    X = torch.randn(N)\n",
    "\n",
    "    # Normalize this point to the surface of the sphere, then scale by radius R\n",
    "    return R * X / torch.norm(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complete BO - loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test a test function\n",
    "\n",
    "\n",
    "\n",
    "maximizing task:\n",
    "\n",
    "let test function to be: $f_1: x,y  \\rightarrow \\frac{1}{x}+y; f_2: x, y \\rightarrow x+y^2$\n",
    "\n",
    "both taking bounds [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = torch.tensor([[1.0]*2,[2.0]*2])\n",
    "dtype =torch.float64\n",
    "def f_1(x):\n",
    "    r = 1/x[:,0]+ x[:,1]\n",
    "    return(-r.unsqueeze(1))\n",
    "\n",
    "def f_2(x):\n",
    "    r = x[:,0]+ x[:,1]**2\n",
    "    return(-r.unsqueeze(1))\n",
    "\n",
    "\n",
    "x = torch.rand(5,2, dtype=dtype)+1\n",
    "y_1 = f_1(x)\n",
    "y_2 = f_2(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 torch.Size([20])\n",
      "22 torch.Size([10])\n",
      "22 torch.Size([10])\n",
      "22 torch.Size([10])\n",
      "22 torch.Size([10])\n",
      "22 torch.Size([10])\n",
      "22 torch.Size([10])\n",
      "22 torch.Size([10])\n",
      "22 torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "beta =4.4\n",
    "a = -1.8\n",
    "b=  -2.5\n",
    "thresholds = torch.tensor([a,b])\n",
    "for batch in range(1):\n",
    "    #not written in loop for now\n",
    "    model_list = []\n",
    "    m = 2\n",
    "    current_model_1 = SingleTaskGP(train_X= x, train_Y= y_1)\n",
    "    model_list.append(current_model_1)\n",
    "    current_model_2 = SingleTaskGP(train_X= x, train_Y= y_2)\n",
    "    model_list.append(current_model_2)\n",
    "    model = ModelListGP(*model_list)\n",
    "\n",
    "    #sample theta from distribution\n",
    "    theta = get_random_sample_on_n_sphere(m,1).abs()\n",
    "\n",
    "    #create auxiliary acquisition\n",
    "    AuxAcq = AuxiliaryAcq(model= model, beta= torch.tensor(beta), theta = theta, ref= thresholds)\n",
    "\n",
    "    #optimize auxiliary acquisition\n",
    "    initializer, acq_value = optimize_acqf(\n",
    "        acq_function = AuxAcq,\n",
    "        q = 5,\n",
    "        num_restarts = 10,\n",
    "        raw_samples = 20,\n",
    "        bounds = bounds\n",
    "    )\n",
    "    #declare\n",
    "    if acq_value < 0: \n",
    "        print(f'decalre infeasibility in {batch+1} rounds')\n",
    "        break\n",
    "\n",
    "    #create acquisition function\n",
    "    HVUCB = HyperVolumeScalarizedUCB(model= model, beta= torch.tensor(beta), theta = theta, ref= thresholds)\n",
    "    #optimize constraint function\n",
    "    candidate, _ = optimize_acqf(\n",
    "        acq_function = HVUCB,\n",
    "        q = 1,\n",
    "        num_restarts = 10,\n",
    "        raw_samples = 20,\n",
    "        nonlinear_inequality_constraints = create_ucb_constraints(beta=beta, model= model, thresholds= thresholds),\n",
    "        #ic_generator = gen_batch_initial_conditions,\n",
    "        \n",
    "        batch_initial_conditions = initializer.view([-1,1,m]),\n",
    "        bounds = bounds,\n",
    "        sequential = True\n",
    "    )\n",
    "    #update data\n",
    "    x = torch.cat([x, candidate],dim=0)\n",
    "    y_1 = torch.cat([y_1, f_1(candidate)], dim = 0)\n",
    "    y_2 = torch.cat([y_2, f_2(candidate)], dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000, 2.0000],\n",
       "        [1.7023, 1.6359],\n",
       "        [1.9485, 1.1150],\n",
       "        [1.6057, 1.2732],\n",
       "        [1.6862, 1.2601]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.0000, 2.0000]],\n",
       "\n",
       "        [[1.7023, 1.6359]],\n",
       "\n",
       "        [[1.9485, 1.1150]],\n",
       "\n",
       "        [[1.6057, 1.2732]],\n",
       "\n",
       "        [[1.6862, 1.2601]]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initializer.view([5,-1,2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
