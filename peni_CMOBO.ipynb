{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from botorch.models.model import Model\n",
    "from botorch.utils import t_batch_mode_transform\n",
    "import torch\n",
    "from botorch.models.model_list_gp_regression import ModelListGP\n",
    "from botorch.models import  SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.utils import standardize\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "from botorch.acquisition import AnalyticAcquisitionFunction\n",
    "from botorch.optim.optimize import optimize_acqf\n",
    "from botorch.optim.initializers import gen_batch_initial_conditions\n",
    "from botorch.utils.transforms import normalize, unnormalize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem setting\n",
    "\n",
    "penicillin function\n",
    "\n",
    "ouputs:\n",
    "\n",
    "P \n",
    "-t\n",
    "-CO2\n",
    "\n",
    "constraints(example):\n",
    "\n",
    "P >= 12\n",
    "\n",
    "-t >= -10\n",
    "\n",
    "-CO2 >= -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.test_functions.multi_objective import Penicillin\n",
    "\n",
    "test_f = Penicillin(negate= True)\n",
    "\n",
    "#initialize data\n",
    "n= 5\n",
    "random_tensor = torch.zeros((n, 7), dtype= torch.float64)\n",
    "\n",
    "for i in range(7):\n",
    "    lower_bound = test_f.bounds[0, i]\n",
    "    upper_bound = test_f.bounds[1, i]\n",
    "    random_tensor[:, i] = lower_bound + (upper_bound - lower_bound) * torch.rand(n)\n",
    "\n",
    "train_X = normalize(random_tensor, test_f.bounds)\n",
    "train_Y = test_f(random_tensor)\n",
    "train_Y = train_Y.to(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperVolumeScalarizedUCB(AnalyticAcquisitionFunction):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        beta: float,\n",
    "        theta: torch.Tensor,\n",
    "        ref: torch.Tensor,\n",
    "        maximize: bool = True,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the HyperVolume Scalarized Upper Confidence Bound Acquisition Function.\n",
    "\n",
    "        Args:\n",
    "            model: A BoTorch model representing the posterior distribution of the objectives.\n",
    "            beta (Tensor of shape [1] or [o]): The exploration-exploitation trade-off parameter(s).\n",
    "            theta (Tensor of shape [o]): The weights used for scalarizing the upper bounds, where `o` is the number of objectives.\n",
    "            maximize (bool): Whether to maximize or minimize the scalarized objective. Defaults to True (maximize).\n",
    "        \"\"\"\n",
    "        super(AnalyticAcquisitionFunction, self).__init__(model)\n",
    "        self.maximize = maximize\n",
    "        self.register_buffer(\"beta\", torch.as_tensor(beta))\n",
    "        self.register_buffer(\"theta\", torch.as_tensor(theta))\n",
    "        self.register_buffer(\"ref\", torch.as_tensor(ref))\n",
    "    @t_batch_mode_transform(expected_q=1)\n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluate the scalarized Upper Confidence Bound on the candidate set X.\n",
    "\n",
    "        Args:\n",
    "            X (Tensor of shape [b, d]): A tensor containing `(b)` batches of `d`-dimensional design points.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape [b]: A tensor containing the scalarized Upper Confidence Bound values for each batch.\n",
    "        \"\"\"\n",
    "        self.beta = self.beta.to(X)\n",
    "        self.theta = self.theta.to(X)\n",
    "        self.ref = self.ref.to(X)\n",
    "        posterior = self.model.posterior(X)\n",
    "        means = posterior.mean.squeeze(dim=-2)  # b x o\n",
    "        std_devs = posterior.variance.squeeze(dim=-2).sqrt()  # b x o\n",
    "        m = means.shape[1]\n",
    "        # Calculate upper confidence bounds for each objective\n",
    "        u_t = means + (self.beta.expand_as(means) * std_devs) - self.ref # b x o\n",
    "\n",
    "        # Apply the scalarization function to the upper bounds\n",
    "        scalarized_ut = torch.min(torch.max(torch.zeros_like(u_t), u_t / self.theta) ** m, dim=-1)[0]  # b\n",
    "\n",
    "        return scalarized_ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ucb_constraints(model, beta: float, thresholds: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Creates a list of non-linear inequality constraints for a multi-output GP model, ensuring that the upper confidence\n",
    "    bounds of the model's outputs are greater than or equal to the specified thresholds.\n",
    "\n",
    "    Args:\n",
    "        model (MultiTaskGP): A multi-output Gaussian Process model.\n",
    "        beta (float): The scalar coefficient for the variance component of the UCB.\n",
    "        thresholds (torch.Tensor): A tensor of thresholds for each output dimension.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[Callable, bool]]: A list of tuples, each containing a callable constraint and a boolean indicating\n",
    "                                      whether the constraint is intra-point (True) or inter-point (False). Each callable\n",
    "                                      takes a tensor `X` of shape [q, d] (where `d` is the dimension of the input space\n",
    "                                      and `q` can be 1 or more representing different design points) and returns a scalar\n",
    "                                      that should be non-negative if the constraint is satisfied.\n",
    "    \"\"\"\n",
    "\n",
    "    def make_constraint(i, threshold):\n",
    "        \"\"\"\n",
    "        Creates a constraint function for the i-th objective.\n",
    "\n",
    "        Args:\n",
    "            i (int): The index of the output dimension for which to create the constraint.\n",
    "            threshold (float): The threshold value that the UCB of the i-th output should meet.\n",
    "\n",
    "        Returns:\n",
    "            Callable: A function that evaluates the constraint across a batch of design points.\n",
    "        \"\"\"\n",
    "        def constraint(X):\n",
    "            X = X.unsqueeze(0)\n",
    "            # Compute posterior at X\n",
    "            posterior = model.posterior(X)\n",
    "            mean = posterior.mean[:, i]  # Extract the mean for the i-th output\n",
    "            variance = posterior.variance[:, i]  # Extract the variance for the i-th output\n",
    "            ucb = mean + beta * variance.sqrt()  # Compute the UCB\n",
    "\n",
    "            # Minimum across all points in the batch to satisfy the constraint for any single design point\n",
    "            return ucb - threshold\n",
    "\n",
    "        return constraint\n",
    "\n",
    "    # Create a list of constraints for each output dimension, all set as intra-point since they evaluate individually\n",
    "    constraints = [(make_constraint(i, thresholds[i]), True) for i in range(thresholds.size(0))]\n",
    "\n",
    "    return constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_sample_on_n_sphere(N, R):\n",
    "    # Return a single sample of a vector of dimension N\n",
    "    # with a uniform distribution on the (N-1)-Sphere surface of radius R.\n",
    "    # RATIONALE: https://mathworld.wolfram.com/HyperspherePointPicking.html\n",
    "    \n",
    "    # Generate a normally distributed point\n",
    "    X = torch.randn(N)\n",
    "\n",
    "    # Normalize this point to the surface of the sphere, then scale by radius R\n",
    "    return R * X / torch.norm(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BO loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "beta =2\n",
    "thresholds = torch.tensor([10, -100, -300])\n",
    "for batch in range(10):\n",
    "    model_list = []\n",
    "    m = 3\n",
    "    for i in range(m):\n",
    "        current_model = SingleTaskGP(train_X= train_X, train_Y= train_Y[:, i].unsqueeze(-1))\n",
    "        model_list.append(current_model)\n",
    "    model = ModelListGP(*model_list)\n",
    "    #test feasibility maximize UCB function TBD\n",
    "\n",
    "\n",
    "    #sample theta from distribution\n",
    "    theta = get_random_sample_on_n_sphere(m,1).abs()\n",
    "    #create acquisition function\n",
    "    HVUCB = HyperVolumeScalarizedUCB(model= model, beta= torch.tensor(beta), theta = theta, ref= thresholds)\n",
    "    #optimize constraint function\n",
    "    candidate, _ = optimize_acqf(\n",
    "        acq_function = HVUCB,\n",
    "        q = 1,\n",
    "        num_restarts = 5,\n",
    "        raw_samples = 5,\n",
    "        nonlinear_inequality_constraints = create_ucb_constraints(beta=beta, model= model, thresholds= thresholds),\n",
    "        ic_generator = gen_batch_initial_conditions,\n",
    "        #batch_initial_conditions = torch.tensor([-0.001,1.0], dtype= dtype).view([1,1,-1]),\n",
    "\n",
    "        #take the standard bounds\n",
    "        bounds = torch.tensor([[0.0]*7, [1.0]*7]),\n",
    "        sequential = True\n",
    "    )\n",
    "    #update data\n",
    "    train_X = torch.cat([train_X, candidate],dim=0)\n",
    "    train_Y = torch.cat([train_Y, test_f(unnormalize(candidate, bounds= test_f.bounds))], dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
