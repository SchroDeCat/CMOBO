{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "customOutput": null,
        "executionStartTime": 1668651350300,
        "executionStopTime": 1668651350308,
        "originalKey": "f27224aa-b567-4a6d-b6b3-74f2ecbfe319",
        "requestMsgId": "df1b7814-2d71-4421-b832-e10d0c1e7743"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import sys\n",
        "\n",
        "\n",
        "tkwargs = {\n",
        "    \"dtype\": torch.double,\n",
        "    \"device\": torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\"),\n",
        "}\n",
        "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/lidiantong/Documents/GitHub/CMOBO/experiments_benchmarks/qParEGO'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "89f8b99f-5cb2-45c9-9df6-7e1d18d4f8c6",
        "showInput": false
      },
      "source": [
        "### Problem setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "customOutput": null,
        "executionStartTime": 1668651350608,
        "executionStopTime": 1668651354486,
        "originalKey": "4227f250-60b5-4c97-b04c-3cfe7a1c410a",
        "requestMsgId": "83e67907-72c3-4bb8-8468-7eb99e616730"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/Users/lidiantong/Documents/GitHub/CMOBO/experiments_benchmarks/qParEGO/../datasets/target_ESOL.pt'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m target_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_ESOL.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m domain_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain_ESOL.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m domain \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(domain_path)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/lidiantong/Documents/GitHub/CMOBO/experiments_benchmarks/qParEGO/../datasets/target_ESOL.pt'"
          ]
        }
      ],
      "source": [
        "target_path = os.path.join(os.getcwd(), '..', 'datasets', 'target_ESOL.pt')\n",
        "domain_path = os.path.join(os.getcwd(), '..', 'datasets', 'domain_ESOL.pt')\n",
        "target = torch.load(target_path)\n",
        "domain = torch.load(domain_path)\n",
        "import random\n",
        "def problem(X: torch.Tensor, tensor: torch.Tensor) -> int:\n",
        "    # Compare the 1*d tensor (row) with each row in the n*d tensor\n",
        "    matches = (tensor == X).all(dim=1)\n",
        "    \n",
        "    # Find the index of the matching row\n",
        "    match_idx = torch.where(matches)[0][-1]\n",
        "    # If a match is found, return the index\n",
        "    \n",
        "    return match_idx.item()\n",
        "\n",
        "    # Stack the list of rows into a tensor and return it\n",
        "    output = torch.stack(output_rows)\n",
        "    return output\n",
        "\n",
        "d = 2000\n",
        "M = 4\n",
        "bounds = torch.zeros(2, domain.shape[1])\n",
        "bounds[0,:] = torch.min(domain, dim = 0)[0]\n",
        "bounds[1,:] = torch.max(domain, dim = 0)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "#need a evaluate_slack function\n",
        "def evaluate_slack(Y, ref = torch.tensor([2.5, 0.5,55,-4]).to(**tkwargs)):\n",
        "    vio_raw = Y -ref\n",
        "    return (vio_raw).sum(dim = -1, keepdim = True)\n",
        "\n",
        "\n",
        "def generate_initial_data(n):\n",
        "    # generate training data\n",
        "    ind = random.sample(range(target.shape[0]), n)\n",
        "    train_x = domain[ind,:]\n",
        "    train_obj = target[ind,:]\n",
        "    # negative values imply feasibility in botorch\n",
        "    train_con = -evaluate_slack(train_obj)\n",
        "    return train_x, train_obj, train_con"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "code_folding": [],
        "customOutput": null,
        "executionStartTime": 1668651354720,
        "executionStopTime": 1668651354729,
        "hidden_ranges": [],
        "originalKey": "192b8d87-b2e3-4223-b193-6399b8643391",
        "requestMsgId": "55d97599-5be9-4a7a-857c-18a9b56bf07d"
      },
      "outputs": [],
      "source": [
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "from botorch.models.model_list_gp_regression import ModelListGP\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "from botorch.utils.sampling import draw_sobol_samples\n",
        "from botorch.utils.transforms import normalize, unnormalize\n",
        "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
        "from gauche.kernels.fingerprint_kernels.tanimoto_kernel import TanimotoKernel\n",
        "from gpytorch.kernels import ScaleKernel\n",
        "base = TanimotoKernel()\n",
        "covar_module = ScaleKernel(\n",
        "base_kernel=base,\n",
        ")\n",
        "\n",
        "\n",
        "def initialize_model(train_x, train_obj, train_con):\n",
        "    # define models for objective and constraint\n",
        "    train_y = torch.cat([train_obj, train_con], dim=-1)\n",
        "    models = []\n",
        "    for i in range(train_y.shape[-1]):\n",
        "        models.append(\n",
        "            SingleTaskGP(\n",
        "                train_x, train_y[..., i : i + 1], outcome_transform=Standardize(m=1), covar_module = covar_module,train_Yvar= torch.zeros((train_x.shape[0],1)) + 0.005**2\n",
        "            )\n",
        "        )\n",
        "    model = ModelListGP(*models)\n",
        "    mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
        "    return mll, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "code_folding": [],
        "customOutput": null,
        "executionStartTime": 1668651355591,
        "executionStopTime": 1668651355682,
        "hidden_ranges": [],
        "originalKey": "a4a23da4-64de-4948-ad92-76b57c023f62",
        "requestMsgId": "f38f70dd-4857-484f-963c-cdfec7d8fc67"
      },
      "outputs": [],
      "source": [
        "from botorch.acquisition.monte_carlo import qExpectedImprovement\n",
        "from botorch.acquisition.objective import GenericMCObjective\n",
        "from botorch.acquisition.multi_objective.monte_carlo import (\n",
        "    qNoisyExpectedHypervolumeImprovement,\n",
        ")\n",
        "from botorch.acquisition.multi_objective.objective import IdentityMCMultiOutputObjective\n",
        "from botorch.optim.optimize import optimize_acqf_discrete\n",
        "from botorch.utils.multi_objective.scalarization import get_chebyshev_scalarization\n",
        "from botorch.utils.sampling import sample_simplex\n",
        "\n",
        "\n",
        "BATCH_SIZE = 1\n",
        "NUM_RESTARTS = 4\n",
        "RAW_SAMPLES = 4\n",
        "\n",
        "standard_bounds = torch.zeros(2, 2, **tkwargs)\n",
        "standard_bounds[1] = 1\n",
        "\n",
        "c = 0\n",
        "\n",
        "def optimize_qparego_and_get_observation(model, train_obj, train_con, sampler):\n",
        "    \"\"\"Samples a set of random weights for each candidate in the batch, performs sequential greedy optimization\n",
        "    of the qParEGO acquisition function, and returns a new candidate and observation.\"\"\"\n",
        "    # sample random weights\n",
        "    weights = sample_simplex(4, **tkwargs).squeeze()\n",
        "    # construct augmented Chebyshev scalarization\n",
        "    scalarization = get_chebyshev_scalarization(weights=weights, Y=train_obj)\n",
        "    # initialize the scalarized objective (w/o constraints)\n",
        "    scalarized_objective = GenericMCObjective(\n",
        "        # the last element of the model outputs is the constraint\n",
        "        lambda Z, X: scalarization(Z[..., :-1]),\n",
        "    )\n",
        "    train_y = torch.cat([train_obj, train_con], dim=-1)\n",
        "    acq_func = qExpectedImprovement(  # pyre-ignore: [28]\n",
        "        model=model,\n",
        "        objective=scalarized_objective,\n",
        "        best_f=scalarized_objective(train_y).max(),\n",
        "        constraints=[lambda Z: Z[..., -1]],\n",
        "        sampler=sampler,\n",
        "    )\n",
        "    # optimize\n",
        "    candidates, acq_v = optimize_acqf_discrete(\n",
        "        acq_function = acq_func,\n",
        "        choices  = domain,\n",
        "        q = 1)\n",
        "    # observe new values\n",
        "    new_x = candidates\n",
        "    new_obj = target[problem(new_x, domain),:].unsqueeze(0)\n",
        "    # negative values imply feasibility in botorch\n",
        "    new_con = -evaluate_slack(new_obj)\n",
        "    return new_x, new_obj, new_con, acq_v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [],
        "customOutput": null,
        "executionStartTime": 1668651356028,
        "executionStopTime": 1668651959470,
        "hidden_ranges": [],
        "originalKey": "4c225d99-6425-4201-ac4a-a042a351c1d3",
        "requestMsgId": "be831f3c-ff7c-4c00-a215-fb021f0c5770"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import warnings\n",
        "from metrics import HV\n",
        "from botorch import fit_gpytorch_mll\n",
        "from botorch.exceptions import BadInitialCandidatesWarning\n",
        "from botorch.sampling.normal import SobolQMCNormalSampler\n",
        "from botorch.utils.multi_objective.hypervolume import Hypervolume\n",
        "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
        "warnings.filterwarnings('ignore')\n",
        "print('O'*50)\n",
        "warnings.filterwarnings(\"ignore\", category=BadInitialCandidatesWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "c = 0\n",
        "random_seeds = [83810, 14592, 3278, 97196, 36048, 32098, 29256, 18289, 96530, 13434, 88696, 97080, 71482, 11395, 77397, 55302, 4165, 3905, 12280, 28657, 30495, 66237, 78907, 3478, 73563,\n",
        "26062, 93850, 85181, 91924, 71426, 54987, 28893, 58878, 77236, 36463, 851, 99458, 20926, 91506, 55392, 44597, 36421, 20379, 28221, 44118, 13396, 12156, 49797, 12676, 47052]\n",
        "N_BATCH =60\n",
        "MC_SAMPLES = 128 if not SMOKE_TEST else 16\n",
        "verbose = True\n",
        "for seed  in random_seeds[:10]:\n",
        "    target = torch.load('target_ESOL.pt')\n",
        "    domain = torch.load('domain_ESOL.pt')\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    hvs_qparego, hvs_random = [], []\n",
        "\n",
        "    # call helper functions to generate initial training data and initialize model\n",
        "    train_x_qparego, train_obj_qparego, train_con_qparego = generate_initial_data(\n",
        "        n= 64\n",
        "    )\n",
        "    train_x_qparego = train_x_qparego.to(torch.float64)\n",
        "    mll_qparego, model_qparego = initialize_model(\n",
        "        train_x_qparego, train_obj_qparego, train_con_qparego\n",
        "    )\n",
        "\n",
        "\n",
        "    train_x_random, train_obj_random, train_con_random = (\n",
        "        train_x_qparego,\n",
        "        train_obj_qparego,\n",
        "        train_con_qparego,\n",
        "    )\n",
        "\n",
        "    '''mll_qnehvi, model_qnehvi = initialize_model(\n",
        "        train_x_qnehvi, train_obj_qnehvi, train_con_qnehvi\n",
        "    )\n",
        "    '''\n",
        "    # compute pareto front\n",
        "    volume = HV(train_obj_qparego, torch.tensor([2.5, 0.5,55,-4]).to(**tkwargs))\n",
        "\n",
        "    hvs_qparego.append(volume)\n",
        "    #hvs_qnehvi.append(volume)\n",
        "    hvs_random.append(volume)\n",
        "    Acq = []\n",
        "    # run N_BATCH rounds of BayesOpt after the initial random batch\n",
        "    for iteration in range(1, N_BATCH + 1):\n",
        "        t0 = time.monotonic()\n",
        "\n",
        "        # fit the models\n",
        "        fit_gpytorch_mll(mll_qparego)\n",
        "\n",
        "\n",
        "        # define the qParEGO and qNEHVI acquisition modules using a QMC sampler\n",
        "        qparego_sampler = SobolQMCNormalSampler(sample_shape=torch.Size([MC_SAMPLES]))\n",
        "    # qnehvi_sampler = SobolQMCNormalSampler(sample_shape=torch.Size([MC_SAMPLES]))\n",
        "\n",
        "        # optimize acquisition functions and get new observations\n",
        "        (\n",
        "            new_x_qparego,\n",
        "            new_obj_qparego,\n",
        "            new_con_qparego,\n",
        "            new_acq_v_qparego\n",
        "        ) = optimize_qparego_and_get_observation(\n",
        "            model_qparego, train_obj_qparego, train_con_qparego, qparego_sampler\n",
        "        )\n",
        "\n",
        "        new_x_random, new_obj_random, new_con_random = generate_initial_data(n=BATCH_SIZE)\n",
        "\n",
        "        # update training points\n",
        "        train_x_qparego = torch.cat([train_x_qparego, new_x_qparego])\n",
        "        train_obj_qparego = torch.cat([train_obj_qparego, new_obj_qparego])\n",
        "        train_con_qparego = torch.cat([train_con_qparego, new_con_qparego])\n",
        "\n",
        "        train_x_random = torch.cat([train_x_random, new_x_random])\n",
        "        train_obj_random = torch.cat([train_obj_random, new_obj_random])\n",
        "        train_con_random = torch.cat([train_con_random, new_con_random])\n",
        "        #append acqvs\n",
        "        Acq.append(new_acq_v_qparego)\n",
        "        # update progress\n",
        "        for hvs_list, train_obj in zip(\n",
        "            (hvs_random, hvs_qparego),\n",
        "            (train_obj_random, train_obj_qparego)\n",
        "        ):\n",
        "            # compute pareto front\n",
        "            volume = HV(train_obj, torch.tensor([2.5, 0.5,55,-4]).to(**tkwargs))\n",
        "            hvs_list.append(volume)\n",
        "        print(f'round{iteration}: ', 'qparego: ', hvs_qparego[-1], 'random: ',hvs_random[-1] )\n",
        "        ###prune candidate###\n",
        "        mask = torch.tensor([True]*target.shape[0])\n",
        "        mask[problem(new_x_qparego, domain)] = False\n",
        "        domain = domain[mask, :]\n",
        "        target = target[mask, :]\n",
        "        ####################\n",
        "\n",
        "        # reinitialize the models so they are ready for fitting on next iteration\n",
        "        # Note: we find improved performance from not warm starting the model hyperparameters\n",
        "        # using the hyperparameters from the previous iteration\n",
        "        mll_qparego, model_qparego = initialize_model(\n",
        "            train_x_qparego, train_obj_qparego, train_con_qparego\n",
        "        )\n",
        "    c +=1\n",
        "    # torch.save(torch.tensor(hvs_qparego), f'hv_qparego_ESOL_{c}.pt')\n",
        "    # torch.save(torch.tensor(train_obj_qparego), f'obj_qparego_ESOL_{c}.pt')\n",
        "    print('O', end='')\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
