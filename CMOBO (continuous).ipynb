{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from botorch.models.model import Model\n",
    "from botorch.utils import t_batch_mode_transform\n",
    "from torch import Tensor\n",
    "from botorch.models.model_list_gp_regression import ModelListGP\n",
    "import torch\n",
    "from botorch.models import  SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.utils import standardize\n",
    "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
    "from botorch.acquisition import AnalyticAcquisitionFunction\n",
    "from botorch.optim.optimize import optimize_acqf\n",
    "from botorch.optim.initializers import gen_batch_initial_conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the acquisition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.acquisition import AnalyticAcquisitionFunction\n",
    "import torch\n",
    "\n",
    "class HyperVolumeScalarizedUCB(AnalyticAcquisitionFunction):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        beta: torch.Tensor,\n",
    "        theta: torch.Tensor,\n",
    "        ref: torch.Tensor,\n",
    "        maximize: bool = True,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the HyperVolume Scalarized Upper Confidence Bound Acquisition Function.\n",
    "\n",
    "        Args:\n",
    "            model: A BoTorch model representing the posterior distribution of the objectives.\n",
    "            beta (Tensor of shape [1] or [o]): The exploration-exploitation trade-off parameter(s).\n",
    "            theta (Tensor of shape [o]): The weights used for scalarizing the upper bounds, where `o` is the number of objectives.\n",
    "            maximize (bool): Whether to maximize or minimize the scalarized objective. Defaults to True (maximize).\n",
    "        \"\"\"\n",
    "        super(AnalyticAcquisitionFunction, self).__init__(model)\n",
    "        self.maximize = maximize\n",
    "        self.register_buffer(\"beta\", torch.as_tensor(beta))\n",
    "        self.register_buffer(\"theta\", torch.as_tensor(theta))\n",
    "        self.register_buffer(\"ref\", torch.as_tensor(ref))\n",
    "    @t_batch_mode_transform(expected_q=1)\n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluate the scalarized Upper Confidence Bound on the candidate set X.\n",
    "\n",
    "        Args:\n",
    "            X (Tensor of shape [b, d]): A tensor containing `(b)` batches of `d`-dimensional design points.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape [b]: A tensor containing the scalarized Upper Confidence Bound values for each batch.\n",
    "        \"\"\"\n",
    "        self.beta = self.beta.to(X)\n",
    "        self.theta = self.theta.to(X)\n",
    "        self.ref = self.ref.to(X)\n",
    "        posterior = self.model.posterior(X)\n",
    "        means = posterior.mean.squeeze(dim=-2)  # b x o\n",
    "        std_devs = posterior.variance.squeeze(dim=-2).sqrt()  # b x o\n",
    "        m = means.shape[1]\n",
    "        # Calculate upper confidence bounds for each objective\n",
    "        u_t = means + (self.beta.expand_as(means) * std_devs) - self.ref # b x o\n",
    "\n",
    "        # Apply the scalarization function to the upper bounds\n",
    "        scalarized_ut = torch.min(torch.max(torch.zeros_like(u_t), u_t / self.theta) ** m, dim=-1)[0]  # b\n",
    "\n",
    "        return scalarized_ut\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check feasibility\n",
    "\n",
    "for discrete case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create constraints for each iteration(for continuous case)\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ucb_constraints(model, beta: float, thresholds: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Creates a list of non-linear inequality constraints for a multi-output GP model, ensuring that the upper confidence\n",
    "    bounds of the model's outputs are greater than or equal to the specified thresholds.\n",
    "\n",
    "    Args:\n",
    "        model (MultiTaskGP): A multi-output Gaussian Process model.\n",
    "        beta (float): The scalar coefficient for the variance component of the UCB.\n",
    "        thresholds (torch.Tensor): A tensor of thresholds for each output dimension.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[Callable, bool]]: A list of tuples, each containing a callable constraint and a boolean indicating\n",
    "                                      whether the constraint is intra-point (True) or inter-point (False). Each callable\n",
    "                                      takes a tensor `X` of shape [q, d] (where `d` is the dimension of the input space\n",
    "                                      and `q` can be 1 or more representing different design points) and returns a scalar\n",
    "                                      that should be non-negative if the constraint is satisfied.\n",
    "    \"\"\"\n",
    "\n",
    "    def make_constraint(i, threshold):\n",
    "        \"\"\"\n",
    "        Creates a constraint function for the i-th objective.\n",
    "\n",
    "        Args:\n",
    "            i (int): The index of the output dimension for which to create the constraint.\n",
    "            threshold (float): The threshold value that the UCB of the i-th output should meet.\n",
    "\n",
    "        Returns:\n",
    "            Callable: A function that evaluates the constraint across a batch of design points.\n",
    "        \"\"\"\n",
    "        def constraint(X):\n",
    "            # Compute posterior at X\n",
    "            posterior = model.posterior(X)\n",
    "            mean = posterior.mean.squeeze(-2)[:, i]  # Extract the mean for the i-th output\n",
    "            variance = posterior.variance.squeeze(-2)[:, i]  # Extract the variance for the i-th output\n",
    "            ucb = mean + beta * variance.sqrt()  # Compute the UCB\n",
    "\n",
    "            # Minimum across all points in the batch to satisfy the constraint for any single design point\n",
    "            return ucb - threshold\n",
    "\n",
    "        return constraint\n",
    "\n",
    "    # Create a list of constraints for each output dimension, all set as intra-point since they evaluate individually\n",
    "    constraints = [(make_constraint(i, thresholds[i]), True) for i in range(thresholds.size(0))]\n",
    "\n",
    "    return constraints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sphere point generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_sample_on_n_sphere(N, R):\n",
    "    # Return a single sample of a vector of dimension N\n",
    "    # with a uniform distribution on the (N-1)-Sphere surface of radius R.\n",
    "    # RATIONALE: https://mathworld.wolfram.com/HyperspherePointPicking.html\n",
    "    \n",
    "    # Generate a normally distributed point\n",
    "    X = torch.randn(N)\n",
    "\n",
    "    # Normalize this point to the surface of the sphere, then scale by radius R\n",
    "    return R * X / torch.norm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5742, -0.0514])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complete BO - loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test a test function\n",
    "\n",
    "\n",
    "\n",
    "maximizing task:\n",
    "\n",
    "let test function to be: $f_1: x,y  \\rightarrow \\frac{1}{x}+y; f_2: x, y \\rightarrow x+y^2$\n",
    "\n",
    "both taking bounds [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = torch.tensor([[1.0]*2,[2.0]*2])\n",
    "dtype =torch.float64\n",
    "def f_1(x):\n",
    "    r = 1/x[:,0]+ x[:,1]\n",
    "    return(r.unsqueeze(1))\n",
    "\n",
    "def f_2(x):\n",
    "    r = x[:,0]+ x[:,1]**2\n",
    "    return(r.unsqueeze(1))\n",
    "\n",
    "\n",
    "x = torch.rand(5,2, dtype=dtype)\n",
    "y_1 = f_1(x)\n",
    "y_2 = f_2(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_1(torch.tensor([[1,2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 2 but got size 1 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m HVUCB \u001b[38;5;241m=\u001b[39m HyperVolumeScalarizedUCB(model\u001b[38;5;241m=\u001b[39m model, beta\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(beta), theta \u001b[38;5;241m=\u001b[39m theta, ref\u001b[38;5;241m=\u001b[39m thresholds)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#optimize constraint function\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m candidate, _ \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_acqf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_function\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mHVUCB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_restarts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnonlinear_inequality_constraints\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcreate_ucb_constraints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthresholds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthresholds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mic_generator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgen_batch_initial_conditions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#update data\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m##x\u001b[39;00m\n\u001b[1;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([train_X, candidate],dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/botorch/optim/optimize.py:567\u001b[0m, in \u001b[0;36moptimize_acqf\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, gen_candidates, sequential, ic_generator, timeout_sec, return_full_tree, retry_on_optimization_warning, **ic_gen_kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m     gen_candidates \u001b[38;5;241m=\u001b[39m gen_candidates_scipy\n\u001b[1;32m    545\u001b[0m opt_acqf_inputs \u001b[38;5;241m=\u001b[39m OptimizeAcqfInputs(\n\u001b[1;32m    546\u001b[0m     acq_function\u001b[38;5;241m=\u001b[39macq_function,\n\u001b[1;32m    547\u001b[0m     bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    565\u001b[0m     ic_gen_kwargs\u001b[38;5;241m=\u001b[39mic_gen_kwargs,\n\u001b[1;32m    566\u001b[0m )\n\u001b[0;32m--> 567\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_acqf_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/botorch/optim/optimize.py:588\u001b[0m, in \u001b[0;36m_optimize_acqf\u001b[0;34m(opt_inputs)\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _optimize_acqf_sequential_q(opt_inputs\u001b[38;5;241m=\u001b[39mopt_inputs)\n\u001b[1;32m    587\u001b[0m \u001b[38;5;66;03m# Batch optimization (including the case q=1)\u001b[39;00m\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/botorch/optim/optimize.py:352\u001b[0m, in \u001b[0;36m_optimize_acqf_batch\u001b[0;34m(opt_inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m         batch_acq_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(batch_acq_values_list)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch_candidates, batch_acq_values, opt_warnings\n\u001b[0;32m--> 352\u001b[0m batch_candidates, batch_acq_values, ws \u001b[38;5;241m=\u001b[39m \u001b[43m_optimize_batch_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m optimization_warning_raised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    355\u001b[0m     (\u001b[38;5;28missubclass\u001b[39m(w\u001b[38;5;241m.\u001b[39mcategory, OptimizationWarning) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m ws)\n\u001b[1;32m    356\u001b[0m )\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimization_warning_raised \u001b[38;5;129;01mand\u001b[39;00m opt_inputs\u001b[38;5;241m.\u001b[39mretry_on_optimization_warning:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/botorch/optim/optimize.py:336\u001b[0m, in \u001b[0;36m_optimize_acqf_batch.<locals>._optimize_batch_candidates\u001b[0;34m()\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m ws:\n\u001b[1;32m    332\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39mOptimizationWarning)\n\u001b[1;32m    333\u001b[0m     (\n\u001b[1;32m    334\u001b[0m         batch_candidates_curr,\n\u001b[1;32m    335\u001b[0m         batch_acq_values_curr,\n\u001b[0;32m--> 336\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched_ics_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macq_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfiltered_gen_kwargs\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m opt_warnings \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ws\n\u001b[1;32m    340\u001b[0m batch_candidates_list\u001b[38;5;241m.\u001b[39mappend(batch_candidates_curr)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/botorch/generation/gen.py:241\u001b[0m, in \u001b[0;36mgen_candidates_scipy\u001b[0;34m(initial_conditions, acquisition_function, lower_bounds, upper_bounds, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, options, fixed_features, timeout_sec)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(shapeX) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m shapeX[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    238\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`batch_limit` must be 1 when non-linear inequality constraints \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mare given.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m         )\n\u001b[0;32m--> 241\u001b[0m     constraints \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mmake_scipy_nonlinear_inequality_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnonlinear_inequality_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnonlinear_inequality_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf_np_wrapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_np_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshapeX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshapeX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m x0 \u001b[38;5;241m=\u001b[39m _arrayify(x0)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(x):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/botorch/optim/parameter_constraints.py:587\u001b[0m, in \u001b[0;36mmake_scipy_nonlinear_inequality_constraints\u001b[0;34m(nonlinear_inequality_constraints, f_np_wrapper, x0, shapeX)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    583\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA nonlinear constraint has to be a tuple of length 2, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    584\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m     )\n\u001b[1;32m    586\u001b[0m nlc, is_intrapoint \u001b[38;5;241m=\u001b[39m constraint\n\u001b[0;32m--> 587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mnonlinear_constraint_is_feasible\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnlc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_intrapoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_intrapoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapeX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    591\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`batch_initial_conditions` must satisfy the non-linear inequality \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    592\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstraints.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    593\u001b[0m     )\n\u001b[1;32m    595\u001b[0m scipy_nonlinear_inequality_constraints \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _make_nonlinear_constraints(\n\u001b[1;32m    596\u001b[0m     f_np_wrapper\u001b[38;5;241m=\u001b[39mf_np_wrapper,\n\u001b[1;32m    597\u001b[0m     nlc\u001b[38;5;241m=\u001b[39mnlc,\n\u001b[1;32m    598\u001b[0m     is_intrapoint\u001b[38;5;241m=\u001b[39mis_intrapoint,\n\u001b[1;32m    599\u001b[0m     shapeX\u001b[38;5;241m=\u001b[39mshapeX,\n\u001b[1;32m    600\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/botorch/optim/parameter_constraints.py:533\u001b[0m, in \u001b[0;36mnonlinear_constraint_is_feasible\u001b[0;34m(nonlinear_inequality_constraint, is_intrapoint, x)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_intrapoint:\n\u001b[0;32m--> 533\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcheck_x\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx__\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx__\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx_\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    534\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/botorch/optim/parameter_constraints.py:533\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_intrapoint:\n\u001b[0;32m--> 533\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43mcheck_x\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx__\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x__ \u001b[38;5;129;01min\u001b[39;00m x_):\n\u001b[1;32m    534\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/botorch/optim/parameter_constraints.py:529\u001b[0m, in \u001b[0;36mnonlinear_constraint_is_feasible.<locals>.check_x\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_x\u001b[39m(x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _arrayify(\u001b[43mnonlinear_inequality_constraint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m NLC_TOL\n",
      "Cell \u001b[0;32mIn[3], line 32\u001b[0m, in \u001b[0;36mcreate_ucb_constraints.<locals>.make_constraint.<locals>.constraint\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstraint\u001b[39m(X):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Compute posterior at X\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     posterior \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     mean \u001b[38;5;241m=\u001b[39m posterior\u001b[38;5;241m.\u001b[39mmean\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)[:, i]  \u001b[38;5;66;03m# Extract the mean for the i-th output\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     variance \u001b[38;5;241m=\u001b[39m posterior\u001b[38;5;241m.\u001b[39mvariance\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)[:, i]  \u001b[38;5;66;03m# Extract the variance for the i-th output\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/botorch/models/gpytorch.py:659\u001b[0m, in \u001b[0;36mModelListGPyTorchModel.posterior\u001b[0;34m(self, X, output_indices, observation_noise, posterior_transform, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m returns_untransformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(mod, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutcome_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m mod\u001b[38;5;241m.\u001b[39moutcome_transform\u001b[38;5;241m.\u001b[39m_is_linear)\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels\n\u001b[1;32m    657\u001b[0m )\n\u001b[1;32m    658\u001b[0m \u001b[38;5;66;03m# NOTE: We're not passing in the posterior transform here. We'll apply it later.\u001b[39;00m\n\u001b[0;32m--> 659\u001b[0m posterior \u001b[38;5;241m=\u001b[39m \u001b[43mModelList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobservation_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobservation_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m returns_untransformed:\n\u001b[1;32m    667\u001b[0m     mvns \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mdistribution \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m posterior\u001b[38;5;241m.\u001b[39mposteriors]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/botorch/models/model.py:519\u001b[0m, in \u001b[0;36mModelList.posterior\u001b[0;34m(self, X, output_indices, observation_noise, posterior_transform, **kwargs)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    517\u001b[0m         obs_noise \u001b[38;5;241m=\u001b[39m observation_noise\n\u001b[1;32m    518\u001b[0m     posteriors\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 519\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midcs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservation_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobs_noise\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m posterior \u001b[38;5;241m=\u001b[39m PosteriorList(\u001b[38;5;241m*\u001b[39mposteriors)\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m posterior_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/botorch/models/gpytorch.py:395\u001b[0m, in \u001b[0;36mBatchedMultiOutputGPyTorchModel.posterior\u001b[0;34m(self, X, output_indices, observation_noise, posterior_transform, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m     X, output_dim_idx \u001b[38;5;241m=\u001b[39m add_output_dim(\n\u001b[1;32m    390\u001b[0m         X\u001b[38;5;241m=\u001b[39mX, original_batch_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_batch_shape\n\u001b[1;32m    391\u001b[0m     )\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m# NOTE: BoTorch's GPyTorchModels also inherit from GPyTorch's ExactGP, thus\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# self(X) calls GPyTorch's ExactGP's __call__, which computes the posterior,\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# rather than e.g. SingleTaskGP's forward, which computes the prior.\u001b[39;00m\n\u001b[0;32m--> 395\u001b[0m mvn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observation_noise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gpytorch/models/exact_gp.py:313\u001b[0m, in \u001b[0;36mExactGP.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m         train_input \u001b[38;5;241m=\u001b[39m train_input\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m*\u001b[39mbatch_shape, \u001b[38;5;241m*\u001b[39mtrain_input\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:])\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m*\u001b[39mbatch_shape, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:])\n\u001b[0;32m--> 313\u001b[0m     full_inputs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# Get the joint distribution for training/test data\u001b[39;00m\n\u001b[1;32m    316\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(ExactGP, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39mfull_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 2 but got size 1 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "beta =2\n",
    "a = 0.7\n",
    "b=  0.7\n",
    "thresholds = torch.tensor([a,b])\n",
    "for batch in range(50):\n",
    "    #not written in loop for now\n",
    "    model_list = []\n",
    "    m = 2\n",
    "    current_model_1 = SingleTaskGP(train_X= x, train_Y= y_1)\n",
    "    model_list.append(current_model_1)\n",
    "    current_model_2 = SingleTaskGP(train_X= x, train_Y= y_2)\n",
    "    model_list.append(current_model_2)\n",
    "    model = ModelListGP(*model_list)\n",
    "\n",
    "    #test feasibility maximize UCB function TBD\n",
    "    \n",
    "\n",
    "    #sample theta from distribution(TBD)\n",
    "    theta = get_random_sample_on_n_sphere(m,1).abs()\n",
    "    #create acquisition function\n",
    "    HVUCB = HyperVolumeScalarizedUCB(model= model, beta= torch.tensor(beta), theta = theta, ref= thresholds)\n",
    "    #optimize constraint function\n",
    "    candidate, _ = optimize_acqf(\n",
    "        acq_function = HVUCB,\n",
    "        q = 1,\n",
    "        num_restarts = 10,\n",
    "        raw_samples = 20,\n",
    "        nonlinear_inequality_constraints = create_ucb_constraints(beta=beta, model= model, thresholds= thresholds),\n",
    "        ic_generator = gen_batch_initial_conditions,\n",
    "        bounds = bounds\n",
    "    )\n",
    "    #update data\n",
    "    ##x\n",
    "    x = torch.cat([train_X, candidate],dim=0)\n",
    "    y_1 = torch.cat([y_1, f_1(candidate)], dim = 0)\n",
    "    y_1 = torch.cat([y_1, f_1(candidate)], dim = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
